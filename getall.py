import cv2
import numpy as np
import matplotlib.pyplot as plt
import os
import json
import datetime
from scipy import ndimage
import glob

plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class BatchOrnamentExtractor:
    """
    æ‰¹é‡é™¶ç“·çº¹é¥°æå–å™¨
    å¤„ç†æŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰å›¾åƒï¼Œå¹¶ä¿å­˜ç»“æœåˆ°è¾“å‡ºç›®å½•
    """
    
    def __init__(self, original_images_dir, saliency_maps_dir, output_dir="./final_output/"):
        """
        åˆå§‹åŒ–æ‰¹é‡æå–å™¨
        
        Args:
            original_images_dir: åŸå§‹å›¾åƒç›®å½•è·¯å¾„
            saliency_maps_dir: æ˜¾è‘—æ€§å›¾ç›®å½•è·¯å¾„  
            output_dir: è¾“å‡ºç»“æœç›®å½•è·¯å¾„
        """
        self.original_images_dir = original_images_dir
        self.saliency_maps_dir = saliency_maps_dir
        self.output_dir = output_dir
        
        # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
        self._create_output_structure()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.processed_count = 0
        self.success_count = 0
        self.failed_count = 0
        self.results = []
    
    def _create_output_structure(self):
        """åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„"""
        os.makedirs(self.output_dir, exist_ok=True)
        
        # åˆ›å»ºå­ç›®å½•
        sub_dirs = [
            "all_ornaments",      # å…¨éƒ¨çº¹é¥°ç»“æœ
            "core_ornaments",     # æ ¸å¿ƒçº¹é¥°ç»“æœ  
            "reports",           # æå–æŠ¥å‘Š
            "visualizations",    # å¯è§†åŒ–ç»“æœ
            "masks"             # æ©æ¨¡æ–‡ä»¶
        ]
        
        for sub_dir in sub_dirs:
            os.makedirs(os.path.join(self.output_dir, sub_dir), exist_ok=True)
    
    def safe_grayscale(self, img):
        """å®‰å…¨çš„ç°åº¦è½¬æ¢"""
        if len(img.shape) == 3:
            B = img[:, :, 0].astype(np.float32)
            G = img[:, :, 1].astype(np.float32)
            R_ch = img[:, :, 2].astype(np.float32)
            gray = (R_ch * 30 + G * 59 + B * 11 + 50) / 100
            return np.clip(gray, 0, 255).astype(np.uint8)
        return img
    
    def corrected_step_three(self, original_image_path, saliency_map_path, debug=False):
        """
        ä¿®æ­£åçš„æ­¥éª¤ä¸‰å®ç°
        """
        # è¯»å–å›¾åƒ
        I = cv2.imread(original_image_path)
        R = cv2.imread(saliency_map_path, cv2.IMREAD_GRAYSCALE)
        
        if I is None or R is None:
            raise ValueError("æ— æ³•è¯»å–å›¾åƒæ–‡ä»¶")
        
        # ç¡®ä¿å›¾åƒå°ºå¯¸ä¸€è‡´
        if I.shape[:2] != R.shape:
            R = cv2.resize(R, (I.shape[1], I.shape[0]))
        
        # æ­¥éª¤3.1: è½¬æ¢ä¸ºç°åº¦å›¾
        I_G = self.safe_grayscale(I)
        
        # å¤„ç†æ˜¾è‘—æ€§å›¾R
        if R.max() <= 1.0:
            R = (R * 255).astype(np.uint8)
        
        # åˆ›å»ºRçš„äºŒè¿›åˆ¶æ©æ¨¡
        if np.max(R) == np.min(R):
            R_binary = np.ones_like(R, dtype=np.uint8)
        else:
            _, R_binary = cv2.threshold(R, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        # ä¿®æ­£ï¼šRGä¸éœ€è¦åŠ æ©è†œï¼Œç›´æ¥ä½¿ç”¨æ˜¾è‘—æ€§å›¾çš„ç°åº¦ç‰ˆæœ¬
        R_G = self.safe_grayscale(R)
        
        # æ­¥éª¤3.2: è®¡ç®—å·®å€¼å›¾åƒ X = RG - IG
        X = R_G.astype(np.int16) - I_G.astype(np.int16)
        
        # æ£€æµ‹å·®å€¼æ–¹å‘å¹¶è°ƒæ•´ç®—æ³•
        if X.max() <= 0:
            X_abs = np.abs(X)
            non_zero_mask = (R_binary > 0)
            
            if np.any(non_zero_mask):
                X_non_zero = X_abs[non_zero_mask]
                valid_values = X_non_zero[np.isfinite(X_non_zero)]
                X_mean = np.mean(valid_values) if len(valid_values) > 0 else 25
                T = (X_mean + 50) / 2
            else:
                T = 25
            
            T = np.clip(T, 5, 100)
            Y = np.zeros_like(X_abs, dtype=np.uint8)
            Y[X_abs >= T] = 255
        else:
            non_zero_mask = (R_binary > 0)
            if np.any(non_zero_mask):
                X_non_zero = X[non_zero_mask]
                valid_values = X_non_zero[np.isfinite(X_non_zero)]
                X_mean = np.mean(valid_values) if len(valid_values) > 0 else 75
                T = (X_mean + 150) / 2
            else:
                T = 75
            
            T = np.clip(T, 10, 200)
            Y = np.zeros_like(X, dtype=np.uint8)
            Y[X >= T] = 255
        
        # æ­¥éª¤3.5: ç»“åˆYå’ŒRçš„æ©æ¨¡
        Y_non_zero = (Y > 0)
        R_non_zero = (R_binary > 0)
        final_mask = Y_non_zero & R_non_zero
        
        # åº”ç”¨å½¢æ€å­¦æ“ä½œ
        kernel = np.ones((5, 5), np.uint8)
        final_mask = cv2.morphologyEx(final_mask.astype(np.uint8), cv2.MORPH_CLOSE, kernel)
        
        # æå–æœ€ç»ˆç»“æœ
        S = cv2.bitwise_and(I, I, mask=final_mask)
        Z = cv2.bitwise_and(I_G, I_G, mask=final_mask)
        
        return S, Z, final_mask
    
    def step_four_core_ornament_extraction(self, S, Z, debug=False):
        """
        ç¬¬å››æ­¥ï¼šæ ¸å¿ƒçº¹é¥°æå–
        """
        # æ­¥éª¤4.1: å½¢æ€å­¦é—­è¿ç®—
        kernel = np.ones((5, 5), np.uint8)
        Zm = cv2.morphologyEx(Z, cv2.MORPH_CLOSE, kernel)
        
        # æ­¥éª¤4.2: è¿é€šåŸŸåˆ†æ
        _, binary = cv2.threshold(Zm, 1, 255, cv2.THRESH_BINARY)
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary, connectivity=8)
        
        components = []
        for i in range(1, num_labels):
            area = stats[i, cv2.CC_STAT_AREA]
            if area < 100:
                continue
            components.append({
                'label': i,
                'area': area,
                'centroid': centroids[i],
                'mask': (labels == i).astype(np.uint8)
            })
        
        if len(components) == 0:
            return np.zeros_like(S), None, components
        
        # æ­¥éª¤4.3: é«˜æ–¯åŠ æƒå®šä½
        height, width = Z.shape
        mu, sigma_sq = 0, 30000
        
        max_weight, core_component = -1, None
        
        for comp in components:
            total_weight = 0
            mask, indices = comp['mask'], np.where(comp['mask'] == 1)
            
            for y, x in zip(indices[0], indices[1]):
                distance = np.sqrt((x - width/2)**2 + (y - height/2)**2)
                weight = (1 / np.sqrt(2 * np.pi * sigma_sq)) * np.exp(-(distance - mu)**2 / (2 * sigma_sq))
                total_weight += weight
            
            comp['weight'] = total_weight
            if total_weight > max_weight:
                max_weight, core_component = total_weight, comp
        
        # åˆ›å»ºæ ¸å¿ƒçº¹é¥°å›¾åƒ
        core_mask = core_component['mask'] * 255
        core_mask = cv2.morphologyEx(core_mask, cv2.MORPH_CLOSE, np.ones((3, 3), np.uint8))
        core_ornament = cv2.bitwise_and(S, S, mask=core_mask)
        
        return core_ornament, core_component, components
    
    def process_single_image(self, original_image_path, saliency_map_path, filename):
        """
        å¤„ç†å•å¼ å›¾åƒ
        """
        try:
            print(f"å¤„ç†å›¾åƒ: {filename}")
            
            # æ­¥éª¤ä¸‰ï¼šæå–å…¨éƒ¨çº¹é¥°
            S, Z, mask = self.corrected_step_three(original_image_path, saliency_map_path)
            
            # æ£€æŸ¥æ­¥éª¤ä¸‰ç»“æœ
            if np.max(S) == 0:
                print(f"è­¦å‘Š: {filename} æ­¥éª¤ä¸‰æœªæå–åˆ°çº¹é¥°ï¼Œä½¿ç”¨æ˜¾è‘—æ€§å›¾ç›´æ¥æå–")
                R = cv2.imread(saliency_map_path, cv2.IMREAD_GRAYSCALE)
                I = cv2.imread(original_image_path)
                if R.max() <= 1.0:
                    R = (R * 255).astype(np.uint8)
                _, binary_mask = cv2.threshold(R, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
                S = cv2.bitwise_and(I, I, mask=binary_mask)
                Z = cv2.cvtColor(S, cv2.COLOR_BGR2GRAY)
            
            # æ­¥éª¤å››ï¼šæ ¸å¿ƒçº¹é¥°æå–
            core_ornament, core_component, all_components = self.step_four_core_ornament_extraction(S, Z)
            
            # ä¿å­˜ç»“æœ
            result_info = self._save_results(S, core_ornament, core_component, 
                                           original_image_path, filename)
            
            self.success_count += 1
            self.results.append({
                'filename': filename,
                'status': 'success',
                'result_info': result_info
            })
            
            print(f"âœ… {filename} å¤„ç†å®Œæˆ")
            return True
            
        except Exception as e:
            print(f"âŒ {filename} å¤„ç†å¤±è´¥: {e}")
            self.failed_count += 1
            self.results.append({
                'filename': filename,
                'status': 'failed',
                'error': str(e)
            })
            return False
    
    def _save_results(self, S, core_ornament, core_component, original_image_path, filename):
        """
        ä¿å­˜å•å¼ å›¾åƒçš„å¤„ç†ç»“æœ
        """
        # è¯»å–åŸå§‹å›¾åƒè·å–å°ºå¯¸ä¿¡æ¯
        I = cv2.imread(original_image_path)
        base_name = os.path.splitext(filename)[0]
        
        result_info = {
            'filename': filename,
            'base_name': base_name,
            'timestamp': datetime.datetime.now().strftime("%Y%m%d_%H%M%S"),
            'file_paths': {}
        }
        
        # ä¿å­˜å…¨éƒ¨çº¹é¥°
        all_color_path = os.path.join(self.output_dir, "all_ornaments", f"{base_name}_all_color.jpg")
        all_gray_path = os.path.join(self.output_dir, "all_ornaments", f"{base_name}_all_gray.jpg")
        cv2.imwrite(all_color_path, S)
        cv2.imwrite(all_gray_path, cv2.cvtColor(S, cv2.COLOR_BGR2GRAY))
        result_info['file_paths']['all_ornaments'] = {
            'color': all_color_path,
            'gray': all_gray_path
        }
        
        # ä¿å­˜æ ¸å¿ƒçº¹é¥°
        core_color_path = os.path.join(self.output_dir, "core_ornaments", f"{base_name}_core_color.jpg")
        core_gray_path = os.path.join(self.output_dir, "core_ornaments", f"{base_name}_core_gray.jpg")
        cv2.imwrite(core_color_path, core_ornament)
        cv2.imwrite(core_gray_path, cv2.cvtColor(core_ornament, cv2.COLOR_BGR2GRAY))
        result_info['file_paths']['core_ornaments'] = {
            'color': core_color_path,
            'gray': core_gray_path
        }
        
        # ä¿å­˜æ©æ¨¡
        if core_component:
            core_mask = core_component['mask'] * 255
            mask_path = os.path.join(self.output_dir, "masks", f"{base_name}_mask.jpg")
            cv2.imwrite(mask_path, core_mask)
            result_info['file_paths']['mask'] = mask_path
        
        # ç”Ÿæˆå¹¶ä¿å­˜æŠ¥å‘Š
        report = self._generate_report(core_component, I.shape, base_name)
        report_path = os.path.join(self.output_dir, "reports", f"{base_name}_report.json")
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        result_info['file_paths']['report'] = report_path
        
        # ç”Ÿæˆå¯è§†åŒ–ç»“æœ
        viz_path = os.path.join(self.output_dir, "visualizations", f"{base_name}_viz.jpg")
        self._create_visualization(I, S, core_ornament, core_component, viz_path)
        result_info['file_paths']['visualization'] = viz_path
        
        return result_info
    
    def _generate_report(self, core_component, image_shape, base_name):
        """ç”Ÿæˆæå–æŠ¥å‘Š"""
        report = {
            "filename": base_name,
            "extraction_time": datetime.datetime.now().isoformat(),
            "original_image_dimensions": {
                "width": int(image_shape[1]),
                "height": int(image_shape[0])
            }
        }
        
        if core_component:
            report.update({
                "status": "success",
                "core_ornament_area": int(core_component['area']),
                "area_percentage": float(core_component['area'] / (image_shape[0] * image_shape[1]) * 100),
                "centroid_position": {
                    "x": float(core_component['centroid'][0]),
                    "y": float(core_component['centroid'][1])
                },
                "weight_value": float(core_component['weight'])
            })
        else:
            report.update({
                "status": "no_core_ornament_detected"
            })
        
        return report
    
    def _create_visualization(self, I, S, core_ornament, core_component, save_path):
        """åˆ›å»ºå¯è§†åŒ–ç»“æœ"""
        # è°ƒæ•´å°ºå¯¸ä»¥ä¾¿æ˜¾ç¤º
        scale_factor = min(800 / I.shape[1], 600 / I.shape[0])
        new_width = int(I.shape[1] * scale_factor)
        new_height = int(I.shape[0] * scale_factor)
        
        I_small = cv2.resize(I, (new_width, new_height))
        S_small = cv2.resize(S, (new_width, new_height))
        core_small = cv2.resize(core_ornament, (new_width, new_height))
        
        # åˆ›å»ºå¯¹æ¯”å›¾
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        
        images = [
            (cv2.cvtColor(I_small, cv2.COLOR_BGR2RGB), "åŸå§‹å›¾åƒ"),
            (cv2.cvtColor(S_small, cv2.COLOR_BGR2RGB), "å…¨éƒ¨çº¹é¥°"),
            (cv2.cvtColor(core_small, cv2.COLOR_BGR2RGB), "æ ¸å¿ƒçº¹é¥°"),
        ]
        
        for i, (img, title) in enumerate(images):
            ax = axes[i//2, i%2]
            ax.imshow(img)
            ax.set_title(title, fontsize=12)
            ax.axis('off')
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        if core_component:
            info_text = f"æ ¸å¿ƒçº¹é¥°ä¿¡æ¯:\né¢ç§¯: {core_component['area']}åƒç´ \n"
            info_text += f"å æ¯”: {core_component['area']/(I.shape[0]*I.shape[1])*100:.2f}%\n"
            info_text += f"æƒå€¼: {core_component['weight']:.4f}"
            axes[1, 1].text(0.5, 0.5, info_text, transform=axes[1, 1].transAxes, 
                           ha='center', va='center', fontsize=10,
                           bbox=dict(boxstyle="round", facecolor="wheat", alpha=0.5))
            axes[1, 1].axis('off')
        
        plt.suptitle('é™¶ç“·çº¹é¥°æå–ç»“æœ', fontsize=16)
        plt.tight_layout()
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
    
    def find_matching_pairs(self):
        """
        æŸ¥æ‰¾åŸå§‹å›¾åƒå’Œæ˜¾è‘—æ€§å›¾çš„åŒ¹é…å¯¹
        """
        # æ”¯æŒçš„å›¾åƒæ ¼å¼
        image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff']
        saliency_extensions = ['*.png', '*.jpg', '*.jpeg']
        
        # è·å–æ‰€æœ‰åŸå§‹å›¾åƒæ–‡ä»¶
        original_files = []
        for ext in image_extensions:
            original_files.extend(glob.glob(os.path.join(self.original_images_dir, ext)))
        
        # è·å–æ‰€æœ‰æ˜¾è‘—æ€§å›¾æ–‡ä»¶
        saliency_files = []
        for ext in saliency_extensions:
            saliency_files.extend(glob.glob(os.path.join(self.saliency_maps_dir, ext)))
        
        # åˆ›å»ºæ–‡ä»¶ååˆ°è·¯å¾„çš„æ˜ å°„
        original_map = {os.path.splitext(os.path.basename(f))[0]: f for f in original_files}
        saliency_map = {os.path.splitext(os.path.basename(f))[0]: f for f in saliency_files}
        
        # æŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶å¯¹
        matching_pairs = []
        common_names = set(original_map.keys()) & set(saliency_map.keys())
        
        for name in common_names:
            matching_pairs.append((original_map[name], saliency_map[name], name))
        
        print(f"æ‰¾åˆ° {len(matching_pairs)} å¯¹åŒ¹é…çš„å›¾åƒæ–‡ä»¶")
        return matching_pairs
    
    def run_batch_processing(self):
        """
        è¿è¡Œæ‰¹é‡å¤„ç†
        """
        print("=" * 70)
        print("å¼€å§‹æ‰¹é‡é™¶ç“·çº¹é¥°æå–")
        print("=" * 70)
        print(f"åŸå§‹å›¾åƒç›®å½•: {self.original_images_dir}")
        print(f"æ˜¾è‘—æ€§å›¾ç›®å½•: {self.saliency_maps_dir}")
        print(f"è¾“å‡ºç›®å½•: {self.output_dir}")
        print("=" * 70)
        
        start_time = datetime.datetime.now()
        
        # æŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶å¯¹
        matching_pairs = self.find_matching_pairs()
        
        if not matching_pairs:
            print("âŒ æœªæ‰¾åˆ°åŒ¹é…çš„å›¾åƒæ–‡ä»¶å¯¹")
            return False
        
        print(f"å¼€å§‹å¤„ç† {len(matching_pairs)} å¯¹å›¾åƒ...")
        print("-" * 70)
        
        # å¤„ç†æ¯ä¸ªåŒ¹é…å¯¹
        for i, (original_path, saliency_path, filename) in enumerate(matching_pairs, 1):
            print(f"[{i}/{len(matching_pairs)}] ", end="")
            self.process_single_image(original_path, saliency_path, filename)
            self.processed_count += 1
        
        # ç”Ÿæˆæ‰¹é‡å¤„ç†æŠ¥å‘Š
        self._generate_batch_report(start_time)
        
        return True
    
    def _generate_batch_report(self, start_time):
        """ç”Ÿæˆæ‰¹é‡å¤„ç†æŠ¥å‘Š"""
        end_time = datetime.datetime.now()
        processing_time = (end_time - start_time).total_seconds()
        
        batch_report = {
            "batch_processing_report": {
                "start_time": start_time.isoformat(),
                "end_time": end_time.isoformat(),
                "processing_time_seconds": processing_time,
                "total_images_processed": self.processed_count,
                "successful_extractions": self.success_count,
                "failed_extractions": self.failed_count,
                "success_rate": self.success_count / self.processed_count * 100 if self.processed_count > 0 else 0
            },
            "individual_results": self.results
        }
        
        report_path = os.path.join(self.output_dir, "batch_processing_report.json")
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(batch_report, f, indent=2, ensure_ascii=False)
        
        # æ‰“å°æ€»ç»“
        print("=" * 70)
        print("æ‰¹é‡å¤„ç†å®Œæˆ!")
        print("=" * 70)
        print(f"æ€»å¤„ç†å›¾åƒæ•°: {self.processed_count}")
        print(f"æˆåŠŸæå–æ•°: {self.success_count}")
        print(f"å¤±è´¥æ•°: {self.failed_count}")
        print(f"æˆåŠŸç‡: {batch_report['batch_processing_report']['success_rate']:.2f}%")
        print(f"å¤„ç†æ—¶é—´: {processing_time:.2f}ç§’")
        print(f"å¹³å‡æ¯å¼ å›¾åƒ: {processing_time/self.processed_count:.2f}ç§’" if self.processed_count > 0 else "N/A")
        print(f"ç»“æœä¿å­˜åœ¨: {self.output_dir}")
        print("=" * 70)

def main():
    """
    ä¸»å‡½æ•°ï¼šæ‰¹é‡å¤„ç†ç¤ºä¾‹
    """
    # é…ç½®è·¯å¾„
    original_images_dir = "./test_data/test_images"  # åŸå§‹å›¾åƒç›®å½•
    saliency_maps_dir = "./test_data/u2net_results"  # æ˜¾è‘—æ€§å›¾ç›®å½•
    output_dir = "./final_output"  # è¾“å‡ºç›®å½•
    
    # åˆ›å»ºæ‰¹é‡æå–å™¨
    extractor = BatchOrnamentExtractor(original_images_dir, saliency_maps_dir, output_dir)
    
    # è¿è¡Œæ‰¹é‡å¤„ç†
    success = extractor.run_batch_processing()
    
    if success:
        print("ğŸ‰ æ‰¹é‡å¤„ç†æˆåŠŸå®Œæˆ!")
    else:
        print("ğŸ’¥ æ‰¹é‡å¤„ç†å¤±è´¥")

if __name__ == "__main__":
    main()